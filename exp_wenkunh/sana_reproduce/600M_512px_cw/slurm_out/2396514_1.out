I0415 00:59:10.208000 3705372 site-packages/torch/distributed/run.py:675] Using nproc_per_node=8.
W0415 00:59:10.208000 3705372 site-packages/torch/distributed/run.py:792] 
W0415 00:59:10.208000 3705372 site-packages/torch/distributed/run.py:792] *****************************************
W0415 00:59:10.208000 3705372 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0415 00:59:10.208000 3705372 site-packages/torch/distributed/run.py:792] *****************************************
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194] Starting elastic_operator with launch configs:
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   entrypoint       : train_scripts/train.py
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   min_nodes        : 2
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   max_nodes        : 2
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   nproc_per_node   : 8
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   run_id           : 14558
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   rdzv_backend     : c10d
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   rdzv_endpoint    : 10.65.11.157:29500
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   rdzv_configs     : {'timeout': 900}
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   max_restarts     : 0
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   monitor_interval : 0.1
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   log_dir          : /tmp/torchelastic_knrueuru
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194]   metrics_cfg      : {}
I0415 00:59:10.208000 3705372 site-packages/torch/distributed/launcher/api.py:194] 
I0415 00:59:15.096000 3448048 site-packages/torch/distributed/run.py:675] Using nproc_per_node=8.
W0415 00:59:15.097000 3448048 site-packages/torch/distributed/run.py:792] 
W0415 00:59:15.097000 3448048 site-packages/torch/distributed/run.py:792] *****************************************
W0415 00:59:15.097000 3448048 site-packages/torch/distributed/run.py:792] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0415 00:59:15.097000 3448048 site-packages/torch/distributed/run.py:792] *****************************************
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194] Starting elastic_operator with launch configs:
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   entrypoint       : train_scripts/train.py
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   min_nodes        : 2
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   max_nodes        : 2
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   nproc_per_node   : 8
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   run_id           : 14558
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   rdzv_backend     : c10d
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   rdzv_endpoint    : 10.65.11.157:29500
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   rdzv_configs     : {'timeout': 900}
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   max_restarts     : 0
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   monitor_interval : 0.1
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   log_dir          : /tmp/torchelastic_qnqpt79y
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194]   metrics_cfg      : {}
I0415 00:59:15.097000 3448048 site-packages/torch/distributed/launcher/api.py:194] 
I0415 00:59:15.113000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:860] [default] starting workers for entrypoint: python
I0415 00:59:15.113000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:677] [default] Rendezvous'ing worker group
I0415 00:59:16.575000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:860] [default] starting workers for entrypoint: python
I0415 00:59:16.576000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:677] [default] Rendezvous'ing worker group
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525] [default] Rendezvous complete for workers. Result:
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   restart_count=0
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   master_addr=cw-dfw-h100-002-249-026.cm.cluster
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   master_port=15263
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   group_rank=0
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   group_world_size=2
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   role_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   global_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   role_world_sizes=[16, 16, 16, 16, 16, 16, 16, 16]
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525]   global_world_sizes=[16, 16, 16, 16, 16, 16, 16, 16]
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:525] 
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/api.py:685] [default] Starting worker group
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525] [default] Rendezvous complete for workers. Result:
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   restart_count=0
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   master_addr=cw-dfw-h100-002-249-026.cm.cluster
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   master_port=15263
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   group_rank=1
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   group_world_size=2
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   local_ranks=[0, 1, 2, 3, 4, 5, 6, 7]
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   role_ranks=[8, 9, 10, 11, 12, 13, 14, 15]
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   global_ranks=[8, 9, 10, 11, 12, 13, 14, 15]
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   role_world_sizes=[16, 16, 16, 16, 16, 16, 16, 16]
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525]   global_world_sizes=[16, 16, 16, 16, 16, 16, 16, 16]
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:525] 
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/api.py:685] [default] Starting worker group
I0415 00:59:17.253000 3448048 site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:298] use_agent_store: True
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:298] use_agent_store: True
I0415 00:59:17.254000 3448048 site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:192] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:192] Environment variable 'TORCHELASTIC_ENABLE_FILE_TIMER' not found. Do not start FileTimerServer.
I0415 00:59:17.254000 3448048 site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:236] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.
I0415 00:59:17.254000 3705372 site-packages/torch/distributed/elastic/agent/server/local_elastic_agent.py:236] Environment variable 'TORCHELASTIC_HEALTH_CHECK_PORT' not found. Do not start health check.
2025-04-15 15:59:40 - [Sana] - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 16
Process index: 0
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-04-15 15:59:40 - [Sana] - INFO - Distributed environment: MULTI_GPU  Backend: nccl
Num processes: 16
Process index: 8
Local process index: 0
Device: cuda:0

Mixed precision type: fp16

2025-04-15 15:59:40 - [Sana] - INFO - Config: 
{
    "data": {
        "data_dir": [
            "data/InternData"
        ],
        "caption_proportion": {
            "prompt": 1
        },
        "external_caption_suffixes": [
            "",
            "_InternVL2-26B",
            "_InternVL2-8B"
        ],
        "external_clipscore_suffixes": [
            "_InternVL2-26B_clip_score",
            "_InternVL2-8B_clip_score",
            "_prompt_clip_score"
        ],
        "clip_thr_temperature": 0.1,
        "clip_thr": 25.0,
        "del_img_clip_thr": 0.0,
        "sort_dataset": false,
        "load_text_feat": false,
        "load_vae_feat": false,
        "transform": "default_train",
        "type": "SanaWebDatasetMS",
        "image_size": 512,
        "hq_only": false,
        "valid_num": 0,
        "data": null,
        "extra": null
    },
    "model": {
        "model": "SanaMS_600M_P1_D28",
        "teacher": null,
        "image_size": 512,
        "mixed_precision": "fp16",
        "fp32_attention": true,
        "load_from": null,
        "discriminator_model": null,
        "teacher_model": null,
        "teacher_model_weight_dtype": null,
        "resume_from": {
            "checkpoint": "latest",
            "load_ema": false,
            "resume_optimizer": true,
            "resume_lr_scheduler": true
        },
        "aspect_ratio_type": "ASPECT_RATIO_512",
        "multi_scale": true,
        "pe_interpolation": 1.0,
        "micro_condition": false,
        "attn_type": "linear",
        "autocast_linear_attn": false,
        "ffn_type": "glumbconv",
        "mlp_acts": [
            "silu",
            "silu",
            null
        ],
        "mlp_ratio": 2.5,
        "use_pe": false,
        "pos_embed_type": "sincos",
        "qk_norm": false,
        "class_dropout_prob": 0.1,
        "linear_head_dim": 32,
        "cross_norm": false,
        "cross_attn_type": "flash",
        "logvar": false,
        "cfg_scale": 4,
        "cfg_embed": false,
        "cfg_embed_scale": 1.0,
        "guidance_type": "classifier-free",
        "pag_applied_layers": [
            8
        ],
        "ladd_multi_scale": true,
        "head_block_ids": null,
        "extra": null
    },
    "vae": {
        "vae_type": "AutoencoderDC",
        "vae_pretrained": "mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers",
        "weight_dtype": "float32",
        "scale_factor": 0.41407,
        "vae_latent_dim": 32,
        "vae_downsample_rate": 32,
        "sample_posterior": true,
        "extra": null
    },
    "text_encoder": {
        "text_encoder_name": "gemma-2-2b-it",
        "caption_channels": 2304,
        "y_norm": true,
        "y_norm_scale_factor": 0.01,
        "model_max_length": 300,
        "chi_prompt": [
            "Given a user prompt, generate an \"Enhanced prompt\" that provides detailed visual descriptions suitable for image generation. Evaluate the level of detail in the user prompt:",
            "- If the prompt is simple, focus on adding specifics about colors, shapes, sizes, textures, and spatial relationships to create vivid and concrete scenes.",
            "- If the prompt is already detailed, refine and enhance the existing details slightly without overcomplicating.",
            "Here are examples of how to transform or refine prompts:",
            "- User Prompt: A cat sleeping -> Enhanced: A small, fluffy white cat curled up in a round shape, sleeping peacefully on a warm sunny windowsill, surrounded by pots of blooming red flowers.",
            "- User Prompt: A busy city street -> Enhanced: A bustling city street scene at dusk, featuring glowing street lamps, a diverse crowd of people in colorful clothing, and a double-decker bus passing by towering glass skyscrapers.",
            "Please generate only the enhanced description for the prompt below and avoid including any additional commentary or evaluations:",
            "User Prompt: "
        ],
        "extra": null
    },
    "scheduler": {
        "train_sampling_steps": 1000,
        "predict_flow_v": true,
        "noise_schedule": "linear_flow",
        "pred_sigma": false,
        "learn_sigma": true,
        "vis_sampler": "flow_dpm-solver",
        "flow_shift": 3.0,
        "weighting_scheme": "logit_normal",
        "weighting_scheme_discriminator": "logit_normal_trigflow",
        "add_noise_timesteps": [
            1.5708
        ],
        "logit_mean": 0.0,
        "logit_std": 1.0,
        "logit_mean_discriminator": 0.0,
        "logit_std_discriminator": 1.0,
        "sigma_data": 0.5,
        "timestep_norm_scale_factor": 1.0,
        "extra": null
    },
    "train": {
        "num_workers": 10,
        "seed": 1,
        "train_batch_size": 64,
        "num_epochs": 100,
        "gradient_accumulation_steps": 1,
        "grad_checkpointing": true,
        "gradient_clip": 0.1,
        "gc_step": 1,
        "optimizer": {
            "betas": [
                0.9,
                0.999,
                0.9999
            ],
            "eps": [
                1e-30,
                1e-16
            ],
            "lr": 0.0001,
            "type": "CAMEWrapper",
            "weight_decay": 0.0
        },
        "optimizer_D": {
            "eps": 1e-10,
            "lr": 0.0001,
            "type": "AdamW",
            "weight_decay": 0.03
        },
        "load_from_optimizer": false,
        "load_from_lr_scheduler": false,
        "resume_lr_scheduler": true,
        "lr_schedule": "constant",
        "lr_schedule_args": {
            "num_warmup_steps": 2000
        },
        "auto_lr": {
            "rule": "sqrt"
        },
        "eval_batch_size": 16,
        "use_fsdp": false,
        "use_flash_attn": false,
        "eval_sampling_steps": 500,
        "lora_rank": 4,
        "log_interval": 20,
        "mask_type": "null",
        "mask_loss_coef": 0.0,
        "load_mask_index": false,
        "snr_loss": false,
        "real_prompt_ratio": 1.0,
        "early_stop_hours": 10000.0,
        "save_image_epochs": 1,
        "save_model_epochs": 5,
        "save_model_steps": 500,
        "visualize": true,
        "null_embed_root": "output/pretrained_models/",
        "valid_prompt_embed_root": "output/tmp_embed/",
        "validation_prompts": [
            "dog",
            "portrait photo of a girl, photograph, highly detailed face, depth of field",
            "Self-portrait oil painting, a beautiful cyborg with golden hair, 8k",
            "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k",
            "A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece"
        ],
        "local_save_vis": true,
        "deterministic_validation": true,
        "online_metric": false,
        "eval_metric_step": 2000,
        "online_metric_dir": "metric_helper",
        "work_dir": "output/debug",
        "skip_step": 0,
        "loss_type": "huber",
        "huber_c": 0.001,
        "num_ddim_timesteps": 50,
        "ema_decay": 0.95,
        "debug_nan": false,
        "ema_update": false,
        "ema_rate": 0.9999,
        "tangent_warmup_steps": 10000,
        "scm_cfg_scale": [
            1.0
        ],
        "cfg_interval": null,
        "scm_logvar_loss": true,
        "norm_invariant_to_spatial_dim": true,
        "norm_same_as_512_scale": false,
        "g_norm_constant": 0.1,
        "g_norm_r": 1.0,
        "show_gradient": false,
        "lr_scale": null,
        "adv_lambda": 1.0,
        "scm_loss": true,
        "scm_lambda": 1.0,
        "loss_scale": 1.0,
        "r1_penalty": false,
        "r1_penalty_weight": 1e-05,
        "diff_timesteps_D": true,
        "suffix_checkpoints": "disc",
        "misaligned_pairs_D": false,
        "discriminator_loss": "cross entropy",
        "largest_timestep": 1.5708,
        "train_largest_timestep": false,
        "largest_timestep_prob": 0.5,
        "extra": null
    },
    "controlnet": null,
    "model_growth": null,
    "work_dir": "output/600M_512px",
    "resume_from": "latest",
    "load_from": null,
    "debug": false,
    "caching": false,
    "report_to": "wandb",
    "tracker_project_name": "sana-baseline",
    "name": "600M_512px",
    "loss_report_name": "loss"
}
2025-04-15 15:59:40 - [Sana] - INFO - World_size: 16, seed: 1
2025-04-15 15:59:40 - [Sana] - INFO - Initializing: DDP for training
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers

[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
wandb: Currently logged in as: hwk22 (han2024) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.19.8
wandb: Run data is saved locally in /lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/wandb/run-20250415_005941-600M_512px
wandb: Run `wandb offline` to turn off syncing.
wandb: Resuming run 600M_512px
wandb: ⭐️ View project at https://wandb.ai/han2024/sana-baseline
wandb: 🚀 View run at https://wandb.ai/han2024/sana-baseline/runs/600M_512px
2025-04-15 15:59:42 - [Sana] - INFO - Config: 
{
    "data": {
        "data_dir": [
            "data/InternData"
        ],
        "caption_proportion": {
            "prompt": 1
        },
        "external_caption_suffixes": [
            "",
            "_InternVL2-26B",
            "_InternVL2-8B"
        ],
        "external_clipscore_suffixes": [
            "_InternVL2-26B_clip_score",
            "_InternVL2-8B_clip_score",
            "_prompt_clip_score"
        ],
        "clip_thr_temperature": 0.1,
        "clip_thr": 25.0,
        "del_img_clip_thr": 0.0,
        "sort_dataset": false,
        "load_text_feat": false,
        "load_vae_feat": false,
        "transform": "default_train",
        "type": "SanaWebDatasetMS",
        "image_size": 512,
        "hq_only": false,
        "valid_num": 0,
        "data": null,
        "extra": null
    },
    "model": {
        "model": "SanaMS_600M_P1_D28",
        "teacher": null,
        "image_size": 512,
        "mixed_precision": "fp16",
        "fp32_attention": true,
        "load_from": null,
        "discriminator_model": null,
        "teacher_model": null,
        "teacher_model_weight_dtype": null,
        "resume_from": {
            "checkpoint": "latest",
            "load_ema": false,
            "resume_optimizer": true,
            "resume_lr_scheduler": true
        },
        "aspect_ratio_type": "ASPECT_RATIO_512",
        "multi_scale": true,
        "pe_interpolation": 1.0,
        "micro_condition": false,
        "attn_type": "linear",
        "autocast_linear_attn": false,
        "ffn_type": "glumbconv",
        "mlp_acts": [
            "silu",
            "silu",
            null
        ],
        "mlp_ratio": 2.5,
        "use_pe": false,
        "pos_embed_type": "sincos",
        "qk_norm": false,
        "class_dropout_prob": 0.1,
        "linear_head_dim": 32,
        "cross_norm": false,
        "cross_attn_type": "flash",
        "logvar": false,
        "cfg_scale": 4,
        "cfg_embed": false,
        "cfg_embed_scale": 1.0,
        "guidance_type": "classifier-free",
        "pag_applied_layers": [
            8
        ],
        "ladd_multi_scale": true,
        "head_block_ids": null,
        "extra": null
    },
    "vae": {
        "vae_type": "AutoencoderDC",
        "vae_pretrained": "mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers",
        "weight_dtype": "float32",
        "scale_factor": 0.41407,
        "vae_latent_dim": 32,
        "vae_downsample_rate": 32,
        "sample_posterior": true,
        "extra": null
    },
    "text_encoder": {
        "text_encoder_name": "gemma-2-2b-it",
        "caption_channels": 2304,
        "y_norm": true,
        "y_norm_scale_factor": 0.01,
        "model_max_length": 300,
        "chi_prompt": [
            "Given a user prompt, generate an \"Enhanced prompt\" that provides detailed visual descriptions suitable for image generation. Evaluate the level of detail in the user prompt:",
            "- If the prompt is simple, focus on adding specifics about colors, shapes, sizes, textures, and spatial relationships to create vivid and concrete scenes.",
            "- If the prompt is already detailed, refine and enhance the existing details slightly without overcomplicating.",
            "Here are examples of how to transform or refine prompts:",
            "- User Prompt: A cat sleeping -> Enhanced: A small, fluffy white cat curled up in a round shape, sleeping peacefully on a warm sunny windowsill, surrounded by pots of blooming red flowers.",
            "- User Prompt: A busy city street -> Enhanced: A bustling city street scene at dusk, featuring glowing street lamps, a diverse crowd of people in colorful clothing, and a double-decker bus passing by towering glass skyscrapers.",
            "Please generate only the enhanced description for the prompt below and avoid including any additional commentary or evaluations:",
            "User Prompt: "
        ],
        "extra": null
    },
    "scheduler": {
        "train_sampling_steps": 1000,
        "predict_flow_v": true,
        "noise_schedule": "linear_flow",
        "pred_sigma": false,
        "learn_sigma": true,
        "vis_sampler": "flow_dpm-solver",
        "flow_shift": 3.0,
        "weighting_scheme": "logit_normal",
        "weighting_scheme_discriminator": "logit_normal_trigflow",
        "add_noise_timesteps": [
            1.5708
        ],
        "logit_mean": 0.0,
        "logit_std": 1.0,
        "logit_mean_discriminator": 0.0,
        "logit_std_discriminator": 1.0,
        "sigma_data": 0.5,
        "timestep_norm_scale_factor": 1.0,
        "extra": null
    },
    "train": {
        "num_workers": 10,
        "seed": 1,
        "train_batch_size": 64,
        "num_epochs": 100,
        "gradient_accumulation_steps": 1,
        "grad_checkpointing": true,
        "gradient_clip": 0.1,
        "gc_step": 1,
        "optimizer": {
            "betas": [
                0.9,
                0.999,
                0.9999
            ],
            "eps": [
                1e-30,
                1e-16
            ],
            "lr": 0.0001,
            "type": "CAMEWrapper",
            "weight_decay": 0.0
        },
        "optimizer_D": {
            "eps": 1e-10,
            "lr": 0.0001,
            "type": "AdamW",
            "weight_decay": 0.03
        },
        "load_from_optimizer": false,
        "load_from_lr_scheduler": false,
        "resume_lr_scheduler": true,
        "lr_schedule": "constant",
        "lr_schedule_args": {
            "num_warmup_steps": 2000
        },
        "auto_lr": {
            "rule": "sqrt"
        },
        "eval_batch_size": 16,
        "use_fsdp": false,
        "use_flash_attn": false,
        "eval_sampling_steps": 500,
        "lora_rank": 4,
        "log_interval": 20,
        "mask_type": "null",
        "mask_loss_coef": 0.0,
        "load_mask_index": false,
        "snr_loss": false,
        "real_prompt_ratio": 1.0,
        "early_stop_hours": 10000.0,
        "save_image_epochs": 1,
        "save_model_epochs": 5,
        "save_model_steps": 500,
        "visualize": true,
        "null_embed_root": "output/pretrained_models/",
        "valid_prompt_embed_root": "output/tmp_embed/",
        "validation_prompts": [
            "dog",
            "portrait photo of a girl, photograph, highly detailed face, depth of field",
            "Self-portrait oil painting, a beautiful cyborg with golden hair, 8k",
            "Astronaut in a jungle, cold color palette, muted colors, detailed, 8k",
            "A photo of beautiful mountain with realistic sunset and blue lake, highly detailed, masterpiece"
        ],
        "local_save_vis": true,
        "deterministic_validation": true,
        "online_metric": false,
        "eval_metric_step": 2000,
        "online_metric_dir": "metric_helper",
        "work_dir": "output/debug",
        "skip_step": 0,
        "loss_type": "huber",
        "huber_c": 0.001,
        "num_ddim_timesteps": 50,
        "ema_decay": 0.95,
        "debug_nan": false,
        "ema_update": false,
        "ema_rate": 0.9999,
        "tangent_warmup_steps": 10000,
        "scm_cfg_scale": [
            1.0
        ],
        "cfg_interval": null,
        "scm_logvar_loss": true,
        "norm_invariant_to_spatial_dim": true,
        "norm_same_as_512_scale": false,
        "g_norm_constant": 0.1,
        "g_norm_r": 1.0,
        "show_gradient": false,
        "lr_scale": null,
        "adv_lambda": 1.0,
        "scm_loss": true,
        "scm_lambda": 1.0,
        "loss_scale": 1.0,
        "r1_penalty": false,
        "r1_penalty_weight": 1e-05,
        "diff_timesteps_D": true,
        "suffix_checkpoints": "disc",
        "misaligned_pairs_D": false,
        "discriminator_loss": "cross entropy",
        "largest_timestep": 1.5708,
        "train_largest_timestep": false,
        "largest_timestep_prob": 0.5,
        "extra": null
    },
    "controlnet": null,
    "model_growth": null,
    "work_dir": "output/600M_512px",
    "resume_from": "latest",
    "load_from": null,
    "debug": false,
    "caching": false,
    "report_to": "wandb",
    "tracker_project_name": "sana-baseline",
    "name": "600M_512px",
    "loss_report_name": "loss"
}
2025-04-15 15:59:42 - [Sana] - INFO - World_size: 16, seed: 1
2025-04-15 15:59:42 - [Sana] - INFO - Initializing: DDP for training
[AutoencoderDC] Loading model from mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  3.06it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.59it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.59it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.59it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.58it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.56it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.51it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.36it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  4.09it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.68it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.46it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.67it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.46it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.68it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.45it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.66it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.45it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.63it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.42it/s]
Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  4.67it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.64it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.41it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.55it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  5.39it/s]
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.91it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.79it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.72it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.71it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.69it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.72it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.92it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:00<00:00,  2.89it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.82it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.62it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.77it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.56it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.74it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.54it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.72it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.52it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.79it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.57it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.65it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.52it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.74it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.58it/s]
Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.70it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:00<00:00,  3.55it/s]
2025-04-15 16:00:20 - [Sana] - INFO - vae type: AutoencoderDC, path: mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers, weight_dtype: torch.float32
2025-04-15 16:00:20 - [Sana] - INFO - Complex Human Instruct: Given a user prompt, generate an "Enhanced prompt" that provides detailed visual descriptions suitable for image generation. Evaluate the level of detail in the user prompt:
- If the prompt is simple, focus on adding specifics about colors, shapes, sizes, textures, and spatial relationships to create vivid and concrete scenes.
- If the prompt is already detailed, refine and enhance the existing details slightly without overcomplicating.
Here are examples of how to transform or refine prompts:
- User Prompt: A cat sleeping -> Enhanced: A small, fluffy white cat curled up in a round shape, sleeping peacefully on a warm sunny windowsill, surrounded by pots of blooming red flowers.
- User Prompt: A busy city street -> Enhanced: A bustling city street scene at dusk, featuring glowing street lamps, a diverse crowd of people in colorful clothing, and a double-decker bus passing by towering glass skyscrapers.
Please generate only the enhanced description for the prompt below and avoid including any additional commentary or evaluations:
User Prompt: 
2025-04-15 16:00:20 - [Sana] - INFO - flow-prediction: True, noise schedule: linear_flow, flow shift: 3.0, flow weighting: logit_normal, logit-mean: 0.0, logit-std: 1.0
2025-04-15 16:00:21 - [Sana] - INFO - vae type: AutoencoderDC, path: mit-han-lab/dc-ae-f32c32-sana-1.1-diffusers, weight_dtype: torch.float32
2025-04-15 16:00:21 - [Sana] - INFO - Complex Human Instruct: Given a user prompt, generate an "Enhanced prompt" that provides detailed visual descriptions suitable for image generation. Evaluate the level of detail in the user prompt:
- If the prompt is simple, focus on adding specifics about colors, shapes, sizes, textures, and spatial relationships to create vivid and concrete scenes.
- If the prompt is already detailed, refine and enhance the existing details slightly without overcomplicating.
Here are examples of how to transform or refine prompts:
- User Prompt: A cat sleeping -> Enhanced: A small, fluffy white cat curled up in a round shape, sleeping peacefully on a warm sunny windowsill, surrounded by pots of blooming red flowers.
- User Prompt: A busy city street -> Enhanced: A bustling city street scene at dusk, featuring glowing street lamps, a diverse crowd of people in colorful clothing, and a double-decker bus passing by towering glass skyscrapers.
Please generate only the enhanced description for the prompt below and avoid including any additional commentary or evaluations:
User Prompt: 
2025-04-15 16:00:21 - [Sana] - INFO - flow-prediction: True, noise schedule: linear_flow, flow shift: 3.0, flow weighting: logit_normal, logit-mean: 0.0, logit-std: 1.0
2025-04-15 16:00:23 - [Sana] - INFO - use pe: False, pos embed type: sincos, position embed interpolation: 1.0, base size: 16
2025-04-15 16:00:23 - [Sana] - INFO - attention type: linear; ffn type: glumbconv; self-attn qk norm: False; cross-attn type: flash;  cross-attn qk norm: False; autocast linear attn: false
[rank3]:[W415 01:00:27.020901779 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 3]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank1]:[W415 01:00:27.351744872 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 1]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank4]:[W415 01:00:27.353719039 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 4]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank5]:[W415 01:00:27.357267266 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 5]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank2]:[W415 01:00:27.357764160 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 2]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-04-15 16:00:27 - [Sana] - INFO - SanaMS:SanaMS_600M_P1_D28, Model Parameters: 591.75M
2025-04-15 16:00:27 - [Sana] - INFO - Constructing dataset SanaWebDatasetMS...
2025-04-15 16:00:27 - [Sana] - INFO - loading from /lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData/wids-meta.json
2025-04-15 16:00:27 - [Sana] - INFO - [SimplyInternal] Loading meta information /lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData/wids-meta.json
2025-04-15 16:00:27 - [Sana] - INFO - [WebShardedList] /lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData/wids-meta.json, base: ('/lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData',), name: diff-elm-dev, nfiles: 3591nbytes: 0, samples: ('35850189',), cache: /home/wenkunh/.cache/_wids_cache/wenkunh-23c87cbc 
2025-04-15 16:00:27 - [Sana] - INFO - Loading external caption json from: original_filename['', '_InternVL2-26B', '_InternVL2-8B'].json
2025-04-15 16:00:27 - [Sana] - INFO - Loading external clipscore json from: original_filename['_InternVL2-26B_clip_score', '_InternVL2-8B_clip_score', '_prompt_clip_score'].json
2025-04-15 16:00:27 - [Sana] - INFO - external caption clipscore threshold: 25.0, temperature: 0.1
2025-04-15 16:00:27 - [Sana] - INFO - Text max token length: 300
2025-04-15 16:00:27 - [Sana] - WARNING - Sort the dataset: False
2025-04-15 16:00:27 - [Sana] - INFO - Dataset SanaWebDatasetMS constructed: time: 0.02 s, length (use/ori): 35850189/35850189
[rank0]:[W415 01:00:27.415547273 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 0]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank6]:[W415 01:00:27.425017510 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 6]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank7]:[W415 01:00:28.747854360 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 7]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank12]:[W415 01:00:28.253682657 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 12]  using GPU 4 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-04-15 16:00:28 - [Sana] - INFO - SanaMS:SanaMS_600M_P1_D28, Model Parameters: 591.75M
2025-04-15 16:00:28 - [Sana] - INFO - Constructing dataset SanaWebDatasetMS...
2025-04-15 16:00:28 - [Sana] - INFO - loading from /lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData/wids-meta.json
2025-04-15 16:00:28 - [Sana] - INFO - [SimplyInternal] Loading meta information /lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData/wids-meta.json
2025-04-15 16:00:28 - [Sana] - INFO - [WebShardedList] /lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData/wids-meta.json, base: ('/lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData',), name: diff-elm-dev, nfiles: 3591nbytes: 0, samples: ('35850189',), cache: /home/wenkunh/.cache/_wids_cache/wenkunh-23c87cbc 
2025-04-15 16:00:28 - [Sana] - INFO - Loading external caption json from: original_filename['', '_InternVL2-26B', '_InternVL2-8B'].json
2025-04-15 16:00:28 - [Sana] - INFO - Loading external clipscore json from: original_filename['_InternVL2-26B_clip_score', '_InternVL2-8B_clip_score', '_prompt_clip_score'].json
2025-04-15 16:00:28 - [Sana] - INFO - external caption clipscore threshold: 25.0, temperature: 0.1
2025-04-15 16:00:28 - [Sana] - INFO - Text max token length: 300
2025-04-15 16:00:28 - [Sana] - WARNING - Sort the dataset: False
2025-04-15 16:00:28 - [Sana] - INFO - Dataset SanaWebDatasetMS constructed: time: 0.02 s, length (use/ori): 35850189/35850189
[rank8]:[W415 01:00:28.792379290 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 8]  using GPU 0 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank15]:[W415 01:00:28.804641074 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 15]  using GPU 7 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank14]:[W415 01:00:28.811037704 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 14]  using GPU 6 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank10]:[W415 01:00:28.823405073 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 10]  using GPU 2 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank13]:[W415 01:00:28.823575819 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 13]  using GPU 5 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank9]:[W415 01:00:28.828675628 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 9]  using GPU 1 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
[rank11]:[W415 01:00:28.852050008 ProcessGroupNCCL.cpp:4561] [PG ID 0 PG GUID 0 Rank 11]  using GPU 3 to perform barrier as devices used by this process are currently unknown. This can potentially cause a hang if this rank to GPU mapping is incorrect. Specify device_ids in barrier() to force use of a particular device, or call init_process_group() with a device_id.
2025-04-15 16:00:36 - [Sana] - WARNING - Using valid_num=0 in config file. Available 40 aspect_ratios: ['0.25', '0.26', '0.27', '0.28', '0.32', '0.33', '0.35', '0.4', '0.42', '0.48', '0.5', '0.52', '0.57', '0.6', '0.68', '0.72', '0.78', '0.82', '0.88', '0.94', '1.0', '1.07', '1.13', '1.21', '1.29', '1.38', '1.46', '1.67', '1.75', '2.0', '2.09', '2.4', '2.5', '2.89', '3.0', '3.11', '3.62', '3.75', '3.88', '4.0']
2025-04-15 16:00:36 - [Sana] - INFO - No cached file is found, dataloader is slow: /home/wenkunh/.cache/_wids_batchsampler_cache/wenkunh-b293b2d1-sort_datasetFalse-hq_onlyFalse-valid_num0-aspect_ratio40-droplastTruedataset_len35850189-num_replicas16-rank0-/lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData.json
2025-04-15 16:00:36 - [Sana] - WARNING - Using valid_num=0 in config file. Available 40 aspect_ratios: ['0.25', '0.26', '0.27', '0.28', '0.32', '0.33', '0.35', '0.4', '0.42', '0.48', '0.5', '0.52', '0.57', '0.6', '0.68', '0.72', '0.78', '0.82', '0.88', '0.94', '1.0', '1.07', '1.13', '1.21', '1.29', '1.38', '1.46', '1.67', '1.75', '2.0', '2.09', '2.4', '2.5', '2.89', '3.0', '3.11', '3.62', '3.75', '3.88', '4.0']
2025-04-15 16:00:36 - [Sana] - INFO - rank-0 Cached file len: 0
2025-04-15 16:00:36 - [Sana] - INFO - No cached file is found, dataloader is slow: /home/wenkunh/.cache/_wids_batchsampler_cache/wenkunh-b293b2d1-sort_datasetFalse-hq_onlyFalse-valid_num0-aspect_ratio40-droplastTruedataset_len35850189-num_replicas16-rank8-/lustre/fsw/portfolios/nvr/users/wenkunh/workspace/code/Sana_fork/data/InternData.json
2025-04-15 16:00:36 - [Sana] - INFO - Automatically adapt lr to 0.00020 (using sqrt scaling rule).
2025-04-15 16:00:36 - [Sana] - INFO - rank-8 Cached file len: 0
2025-04-15 16:00:36 - [Sana] - INFO - Automatically adapt lr to 0.00020 (using sqrt scaling rule).
2025-04-15 16:00:36 - [Sana] - INFO - CAMEWrapper Optimizer: total 436 param groups, 436 are learnable, 0 are fix. Lr group: 436 params with lr 0.00020; Weight decay group: 436 params with weight decay 0.0.
2025-04-15 16:00:36 - [Sana] - INFO - Lr schedule: constant, num_warmup_steps:32000.
2025-04-15 16:00:36 - [Sana] - WARNING - Basic Setting: lr: 0.00020, bs: 64, gc: True, gc_accum_step: 1, qk norm: False, fp32 attn: True, attn type: linear, ffn type: glumbconv, text encoder: gemma-2-2b-it, captions: {'prompt': 1}, precision: fp16
2025-04-15 16:00:36 - [Sana] - INFO - CAMEWrapper Optimizer: total 436 param groups, 436 are learnable, 0 are fix. Lr group: 436 params with lr 0.00020; Weight decay group: 436 params with weight decay 0.0.
2025-04-15 16:00:36 - [Sana] - INFO - Lr schedule: constant, num_warmup_steps:32000.
2025-04-15 16:00:36 - [Sana] - WARNING - Basic Setting: lr: 0.00020, bs: 64, gc: True, gc_accum_step: 1, qk norm: False, fp32 attn: True, attn type: linear, ffn type: glumbconv, text encoder: gemma-2-2b-it, captions: {'prompt': 1}, precision: fp16
2025-04-15 16:00:36 - [Sana] - INFO - Set seed: 0
2025-04-15 16:00:36 - [Sana] - INFO - Set seed: 0
2025-04-15 16:00:59 - [Sana] - INFO - Epoch: 1 | Global Step: 1 | Local Step: 1 // 35009, total_eta: 925 days, 13:14:55, epoch_eta:9 days, 6:07:34, time: all:1.142, model:0.097, data:0.880, lm:0.056, vae:0.108, lr:0.000e+00, Cap: InternVL2-26B, s:(16, 16), loss:3.9560, grad_norm:inf
2025-04-15 16:00:59 - [Sana] - INFO - Running validation... 
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 32.48it/s] 42%|████▏     | 8/19 [00:00<00:00, 32.72it/s] 63%|██████▎   | 12/19 [00:00<00:00, 32.61it/s] 84%|████████▍ | 16/19 [00:00<00:00, 32.80it/s]100%|██████████| 19/19 [00:00<00:00, 34.49it/s]
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 32.85it/s] 42%|████▏     | 8/19 [00:00<00:00, 32.89it/s] 63%|██████▎   | 12/19 [00:00<00:00, 32.98it/s] 84%|████████▍ | 16/19 [00:00<00:00, 33.12it/s]100%|██████████| 19/19 [00:00<00:00, 34.97it/s]
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 35.27it/s] 42%|████▏     | 8/19 [00:00<00:00, 35.12it/s] 63%|██████▎   | 12/19 [00:00<00:00, 35.20it/s] 84%|████████▍ | 16/19 [00:00<00:00, 35.29it/s]100%|██████████| 19/19 [00:00<00:00, 37.22it/s]
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 35.23it/s] 42%|████▏     | 8/19 [00:00<00:00, 35.14it/s] 63%|██████▎   | 12/19 [00:00<00:00, 35.21it/s] 84%|████████▍ | 16/19 [00:00<00:00, 35.16it/s]100%|██████████| 19/19 [00:00<00:00, 37.11it/s]
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 35.25it/s] 42%|████▏     | 8/19 [00:00<00:00, 35.26it/s] 63%|██████▎   | 12/19 [00:00<00:00, 35.31it/s] 84%|████████▍ | 16/19 [00:00<00:00, 35.29it/s]100%|██████████| 19/19 [00:00<00:00, 37.24it/s]
wandb: WARNING Tried to log to step 1 that is less than the current step 30. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 34.58it/s] 42%|████▏     | 8/19 [00:00<00:00, 34.63it/s] 63%|██████▎   | 12/19 [00:00<00:00, 34.85it/s] 84%|████████▍ | 16/19 [00:00<00:00, 35.12it/s]100%|██████████| 19/19 [00:00<00:00, 36.94it/s]
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 35.34it/s] 42%|████▏     | 8/19 [00:00<00:00, 35.32it/s] 63%|██████▎   | 12/19 [00:00<00:00, 35.10it/s] 84%|████████▍ | 16/19 [00:00<00:00, 35.16it/s]100%|██████████| 19/19 [00:00<00:00, 37.13it/s]
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 34.89it/s] 42%|████▏     | 8/19 [00:00<00:00, 35.04it/s] 63%|██████▎   | 12/19 [00:00<00:00, 35.05it/s] 84%|████████▍ | 16/19 [00:00<00:00, 35.05it/s]100%|██████████| 19/19 [00:00<00:00, 36.82it/s]
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 35.44it/s] 42%|████▏     | 8/19 [00:00<00:00, 35.38it/s] 63%|██████▎   | 12/19 [00:00<00:00, 35.33it/s] 84%|████████▍ | 16/19 [00:00<00:00, 35.02it/s]100%|██████████| 19/19 [00:00<00:00, 37.10it/s]
  0%|          | 0/19 [00:00<?, ?it/s] 21%|██        | 4/19 [00:00<00:00, 35.50it/s] 42%|████▏     | 8/19 [00:00<00:00, 35.47it/s] 63%|██████▎   | 12/19 [00:00<00:00, 35.48it/s] 84%|████████▍ | 16/19 [00:00<00:00, 35.48it/s]100%|██████████| 19/19 [00:00<00:00, 37.42it/s]
wandb: WARNING Tried to log to step 2 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 3 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 4 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 5 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 6 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 7 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 8 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 9 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 10 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 11 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 12 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 13 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 14 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 15 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 16 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 17 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 18 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 19 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-04-15 16:02:09 - [Sana] - INFO - Epoch: 1 | Global Step: 20 | Local Step: 20 // 35009, total_eta: 188 days, 0:39:45, epoch_eta:1 day, 21:06:04, time: all:3.498, model:0.661, data:1.137, lm:0.456, vae:0.842, lr:1.900e-06, Cap: prompt, s:(16, 16), loss:2.9009, grad_norm:9.1181
wandb: WARNING Tried to log to step 20 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 21 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 22 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 23 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 24 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 25 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 26 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 27 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 28 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 29 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
wandb: WARNING Tried to log to step 30 that is less than the current step 31. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.
2025-04-15 16:03:08 - [Sana] - INFO - Epoch: 1 | Global Step: 40 | Local Step: 40 // 35009, total_eta: 153 days, 8:45:59, epoch_eta:1 day, 12:45:57, time: all:2.930, model:0.749, data:0.824, lm:0.481, vae:0.875, lr:3.900e-06, Cap: InternVL2-8B, s:(12, 21), loss:1.7202, grad_norm:1.9362
2025-04-15 16:03:57 - [Sana] - INFO - Epoch: 1 | Global Step: 60 | Local Step: 60 // 35009, total_eta: 135 days, 14:45:58, epoch_eta:1 day, 8:29:32, time: all:2.471, model:0.727, data:0.384, lm:0.483, vae:0.875, lr:5.900e-06, Cap: InternVL2-8B, s:(16, 16), loss:1.2866, grad_norm:2.0021
2025-04-15 16:04:53 - [Sana] - INFO - Epoch: 1 | Global Step: 80 | Local Step: 80 // 35009, total_eta: 130 days, 4:13:13, epoch_eta:1 day, 7:10:17, time: all:2.810, model:0.695, data:0.755, lm:0.484, vae:0.874, lr:7.900e-06, Cap: prompt, s:(16, 16), loss:1.2070, grad_norm:2.1053
2025-04-15 16:06:00 - [Sana] - INFO - Epoch: 1 | Global Step: 100 | Local Step: 100 // 35009, total_eta: 131 days, 2:02:29, epoch_eta:1 day, 7:22:17, time: all:3.325, model:0.747, data:1.222, lm:0.480, vae:0.874, lr:9.900e-06, Cap: prompt, s:(16, 16), loss:1.1721, grad_norm:1.8816
2025-04-15 16:06:56 - [Sana] - INFO - Epoch: 1 | Global Step: 120 | Local Step: 120 // 35009, total_eta: 128 days, 4:57:35, epoch_eta:1 day, 6:39:54, time: all:2.809, model:0.696, data:0.757, lm:0.480, vae:0.874, lr:1.190e-05, Cap: InternVL2-8B, s:(19, 13), loss:1.1541, grad_norm:1.7028
